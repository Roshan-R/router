---
title: Deploy on Kubernetes
description: Self-hosted deployment of Apollo Router on Kubernetes
---

import { Link } from 'gatsby';
import ElasticNotice from '../../shared/elastic-notice.mdx';
import HelmShowOutput from '../../shared/helm-show-router-output.mdx';
import K8SManualConfig from '../../shared/k8s-manual-config.mdx';
import RouterCommonConfig from '../../shared/router-common-config.mdx';

Learn how to deploy a self-hosted supergraph with GraphOS and the Apollo Router on Kubernetes: 

* Get the Helm chart provided with each release of the router.
* Divide a router configuration between one chart for common settings across all environments, and a separate chart for each specific environment.
* Choose chart settings that best migrate from gateway to the router.
* Install your Helm charts to deploy the router.

<ElasticNotice />

## About the router Helm chart

[Helm](https://helm.sh) is a package manager for Kubernetes. You create a Helm _chart_ to describe the resources in a package then install the chart with Helm to deploy the package on Kubernetes (k8s).

Apollo provides an application Helm chart with each release of Apollo Router in GitHub. Each released Helm chart sets specific values for the router, including:

* Coprocessor
* Header propagation
* Max request sizes
* Hot reload
* CORS
* Metrics and labels


## Get the router Helm chart

The Helm chart for each release of the Apollo Router is available from the router's GitHub repository in `<repo>/helm/chart/router`. 

> For example, the Helm chart of the latest release of the router is available [here](https://github.com/apollographql/router/tree/v1.31.1/helm/chart/router).

Since the router v0.14.0, Apollo has also released a Helm chart for the router as an [Open Container Initiative (OCI)](https://helm.sh/docs/topics/registries/) image in our GitHub Container registry. 

> The path to the OCI router chart is `oci://ghcr.io/apollographql/helm-charts/router`.

<ExpansionPanel title="Click to expand example chart for router v1.31.0">

The values of the Helm chart for Apollo Router v1.31.0 in the GitHub container repository, as output by the `helm show` command:

```bash
helm show values oci://ghcr.io/apollographql/helm-charts/router
```

<HelmShowOutput/>

</ExpansionPanel>

## Separate configurations per environment

To support your different deployment configurations for different environments (development, staging, production, etc.), Apollo recommends separating your configuration values into separate files (`values.yaml`):

- A **common** file, which contains values that apply across all environments.
- A unique **environment** file per environment, which includes and overrides the values from the common chart while adding new environment-specific values.

### Common value configuration

Configuring a `values.yaml` file for settings common across environments.

<ExpansionPanel title="Example router Helm chart for common configuration across environments">

<RouterCommonConfig/>

</ExpansionPanel>

(TODO: explain `fullnameOverride`)

Setting router command-line arguments and YAML config file keys/values. 

```yaml title="values.yaml"
router:
  router:
    # args: router binary command-line args
    args: [<router-command-line-args>]
    # configuration: router config 
    configuration:
      ...
```

Configure Rhai script path and entry point.

```yaml title="values.yaml"
router:
  router:
    configuration:
      rhai:
        scripts: <rhai-scripts-path>
        main: <rhai-main-script>.rhai
```

Configure metrics endpoints.

```yaml title="values.yaml"
router:
  router:
    configuration:
      telemetry:
        metrics:
          prometheus:
            enabled: true
          otlp:
            temporality: delta
            endpoint: <otlp-endpoint-addr>
```

Coprocessor container configuration

```yaml title="values.yaml"
router:
  router:
    configuration:
      coprocessor:
        timeout: 3s
        url: <coprocessor-ip>:<coprocessor-container-port>
        router:
          request:
            ...
          response:
            ...
        subgraph:
  extraContainers:
    - name: <coprocessor-app-name>
      image: <coprocessor-app-image>
      ports:
        - containerPort: <coprocessor-container-port>
      env:
        ...

```

#### Configuring migration from gateway

The gateway's maximum supported request size is 20MB, which is different than the router's default maximum request size, so it needs to be configured.

```yaml title="values.yaml"
router:
  router:
    configuration:
      limits:
        experimental_http_max_request_bytes: 20000000 #20MB
```

The router's timeout is increased to accommodate slow subgraphs. Only HTTP 1.1 suport is enabled.

```yaml title="values.yaml"
router:
  router:
    configuration:
      traffic_shaping:
        router:
          timeout: 6min
        all:
          experimental_enable_http2: false
          timeout: 5min
```

Support for `@defer` is unsupported in gateway, so it needs to be disabled in the router.

```yaml title="values.yaml"
router:
  router:
    configuration:
      supergraph:
        defer_support: false
```

The gateway propagates subgraph errors to clients, but the router doesn't by default, so it needs to be configured to propagate subgraph errors.

```yaml title="values.yaml"
router:
  router:
    configuration:
      include_subgraph_errors:
        all: true
```

## Deploy router with Helm

### Install Helm

* Install [Helm](https://helm.sh/docs/intro/install/) **version 3**. The Apollo Router's Helm chart requires Helm v3.

> ⚠️ Your Kubernetes version must be compatible with Helm v3. For details, see [Helm Version Support Policy](https://helm.sh/docs/topics/version_skew/#supported-version-skew).

### Set up cluster

Install the tools and provision the infrastructure for your Kubernetes cluster.

> For example, see the [Setup from Apollo's Build a Supergraph tutorial](https://github.com/apollosolutions/build-a-supergraph/tree/main/01-setup#01---setup). It provides steps you can reference for gathering accounts and credentials for your cloud platform (GCP or AWS), provisioning resources, and deploying your subgraphs.

(TODO: refine the steps between this #set-up-cluster and the next #set-up-self-hosted-router)

### Set up self-hosted router

Set up a self-hosted router by following the [first six steps of the self-hosted router quickstart](/graphos/quickstart/self-hosted), and stopping when you reach step [7. Deploy your router and connect clients](https://www.apollographql.com/docs/graphos/quickstart/self-hosted/#7-deploy-your-router-and-connect-clients).


## Install router Helm chart

You can install the router chart from either a local repository or the container registry.

### Install chart from container registry

* Login to the container registry by following the guide to [authenticating to the GitHub container registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry#authenticating-to-the-container-registry).

* After logging in, verify your access to the registry by showing the latest router chart from `helm`:

  ```bash
  helm show values oci://ghcr.io/apollographql/helm-charts/router
  ```

* Install the OCI image from the GiHub container registry:

  ```bash title="OCI registry"
  helm install --set router.configuration.telemetry.metrics.prometheus.enabled=true --set managedFederation.apiKey="<graph-api-key>" --set managedFederation.graphRef="<graph-ref>" --create-namespace --namespace router-deploy router-test oci://ghcr.io/apollographql/helm-charts/router --version 1.0.0-rc.8 --values router/values.yaml
  ```

### Install Helm chart from local repository

* Clone the [router repository](https://github.com/apollographql/router).

* Change to the directory in your local repo with the router chart:

  ```bash
  cd <repo-directory>/helm/chart
  ```

* Install the local chart, `router`:

  ```bash title="Local repository"
  helm install --set router.configuration.telemetry.metrics.prometheus.enabled=true --set managedFederation.apiKey="<graph-api-key>" --set managedFederation.graphRef="<graph-ref>" --create-namespace --namespace router-deploy router-test router --values router/values.yaml
  ```

  (TODO: clean up and describe the used helm install flags)

  ```
  In both the following examples, we are using helm to install the router:
  - into namespace "router-deploy" (create namespace if it doesn't exist)
  - with helm install name "router-test"
  - with support for prometheus enabled
  ```

## Verify Helm chart deployment

After the router Helm chart has been installed, you can check on the status of the Helm deployment:

```bash
helm list --namespace router-deploy
```

## TODO (other topics to add)

### Kubernetes Configuration

If you aren't familiar with Helm, the following example illustrates how you could do the same thing manually or as a base for [kustomize](https://kustomize.io/).

<ExpansionPanel title="Click to expand example manual k8s configuration">

This example is generated using `helm template` to generate the required Kubernetes configuration from our Helm chart (with Helm management annotations removed).

<K8SManualConfig/>
</ExpansionPanel>


## The health endpoint

The router supports a health endpoint. You can see from the examples above how it can be used in a kubernetes deployment.

If you had a router running on port 8088 on your localhost, you could exercise the health endpoint as follows:

```bash
curl "http://localhost:8088/health"
{"status":"UP"}
```

If you had a router running on your localhost, with default health-check configuration, you could exercise the health endpoint as follows:

curl "http://localhost:8088/health"


## Using `istio` with the router

The [istio service mesh](https://istio.io/) is a very popular choice for enhanced traffic routing within Kubernetes.

`istio-proxy` pod injection can cause an [issue](https://github.com/apollographql/router/issues/3533) in the router. The router may start executing at the same time that istio is reconfiguring networking for the router pod. This is an issue with `istio`, not the router, and you can resolve it by following the advice in [istio's injection documentation](https://istio.io/latest/docs/ops/common-problems/injection/#pod-or-containers-start-with-network-issues-if-istio-proxy-is-not-ready).


